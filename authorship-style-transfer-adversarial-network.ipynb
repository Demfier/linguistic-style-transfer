{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file_path = \"data/c50-articles.txt\"\n",
    "label_file_path = \"data/c50-labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of texts into integer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 100)\n"
     ]
    }
   ],
   "source": [
    "text_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "with open(text_file_path) as text_file:\n",
    "    text_tokenizer.fit_on_texts(text_file)\n",
    "    \n",
    "with open(text_file_path) as text_file:\n",
    "    integer_text_sequences = text_tokenizer.texts_to_sequences(text_file)\n",
    "\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "     integer_text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "print(padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 54\n"
     ]
    }
   ],
   "source": [
    "SOS_INDEX = text_tokenizer.word_index['<sos>']\n",
    "EOS_INDEX = text_tokenizer.word_index['<eos>']\n",
    "print(SOS_INDEX, EOS_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of labels to one-hot represenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 50)\n"
     ]
    }
   ],
   "source": [
    "label_tokenizer =  tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
    "\n",
    "with open(label_file_path) as label_file:\n",
    "    label_tokenizer.fit_on_texts(label_file)\n",
    "\n",
    "with open(label_file_path) as label_file:\n",
    "    label_sequences = label_tokenizer.texts_to_sequences(label_file)\n",
    "\n",
    "NUM_LABELS = len(label_tokenizer.word_index)\n",
    "one_hot_labels = np.asarray(list(\n",
    "    map(lambda x: np.eye(NUM_LABELS, k=x[0])[0], label_sequences)))\n",
    "\n",
    "print(one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerativeAdversarialNetwork():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.build_model()\n",
    "        \n",
    "    def get_sentence_representation(self, index_sequence, word_embeddings):\n",
    "        \n",
    "        embedded_sequence = tf.nn.embedding_lookup(\n",
    "            word_embeddings, index_sequence, name=\"embedded_sequence\")\n",
    "\n",
    "        lstm_cell_fw = tf.contrib.rnn.BasicLSTMCell(num_units=128, name=\"lstm_cell_fw_content\")\n",
    "        lstm_cell_bw = tf.contrib.rnn.BasicLSTMCell(num_units=128, name=\"lstm_cell_bw_content\")\n",
    "\n",
    "        rnn_outputs, rnn_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=lstm_cell_fw, cell_bw=lstm_cell_bw, inputs=embedded_sequence, \n",
    "            dtype=tf.float32, time_major=False)\n",
    "        rnn_state = tf.concat([rnn_states[0].h, rnn_states[1].h], axis=1)\n",
    "\n",
    "        return rnn_state\n",
    "\n",
    "    def get_content_representation(self, sentence_representation):\n",
    "        \n",
    "        dense_content = tf.layers.dense(\n",
    "            inputs=sentence_representation, units=128, \n",
    "            activation=tf.nn.relu, name=\"content_representation\")\n",
    "\n",
    "        return dense_content\n",
    "\n",
    "    def get_style_representation(self, sentence_representation):\n",
    "        \n",
    "        dense_style = tf.layers.dense(\n",
    "            inputs=sentence_representation, units=128, \n",
    "            activation=tf.nn.relu, name=\"style_representation\")\n",
    "        return dense_style\n",
    "\n",
    "    def get_label_prediction(self, content_representation):\n",
    "\n",
    "        dense_1 = tf.layers.dense(\n",
    "            inputs=content_representation, units=NUM_LABELS, \n",
    "            activation=tf.nn.relu, name=\"dense_1\")\n",
    "        \n",
    "        softmax_output = tf.nn.softmax(dense_1, name=\"label_prediction\")\n",
    "\n",
    "        return softmax_output\n",
    "    \n",
    "    def generate_output_sequence(self, word_embeddings, style_representation, \n",
    "                                 content_representation):\n",
    "        last_predicted_word_index = SOS_INDEX\n",
    "        predicted_words = list()\n",
    "        \n",
    "        for i in range(MAX_SEQUENCE_LENGTH):\n",
    "            last_word_embedding = tf.gather_nd(\n",
    "                word_embeddings, [last_predicted_word_index], name='last_word_embedding')\n",
    "#             print(\"last_word_embedding: {}\".format(last_word_embedding))\n",
    "            \n",
    "            batch_size = tf.shape(style_representation)[0]\n",
    "#             print(\"batch_size: {}\".format(batch_size))\n",
    "            \n",
    "            tiled_last_word_embedding = tf.tile(\n",
    "                input=last_word_embedding,  multiples=[batch_size], name=\"tiled_last_word_embedding\")\n",
    "#             print(\"tiled_last_word_embedding: {}\".format(tiled_last_word_embedding))\n",
    "            \n",
    "            matrix = tf.reshape(tiled_last_word_embedding, [batch_size, 300])\n",
    "#             print(\"matrix: {}\".format(matrix))\n",
    "        \n",
    "            intermediate_representation = tf.concat(\n",
    "                values=[matrix, style_representation, content_representation],\n",
    "                axis=1, name='intermediate_representation')\n",
    "#             print(\"intermediate_representation: {}\".format(intermediate_representation))\n",
    "            \n",
    "            dense_intermediate_representation = tf.layers.dense(\n",
    "                inputs=intermediate_representation, units=VOCAB_SIZE + 1, \n",
    "                activation=tf.nn.relu, name=\"dense_intermediate_representation\", \n",
    "                reuse=tf.AUTO_REUSE)\n",
    "            \n",
    "            softmax = tf.nn.softmax(\n",
    "                dense_intermediate_representation, name=\"softmax\")\n",
    "            \n",
    "#             word_prediction = tf.contrib.seq2seq.hardmax(\n",
    "#                 softmax, name=\"word_prediction\")\n",
    "#             print(\"word_prediction: {}\".format(word_prediction))\n",
    "\n",
    "            predicted_words.append(softmax)\n",
    "            \n",
    "            last_predicted_word_index = tf.argmax(\n",
    "                softmax, axis=1, name=\"last_predicted_word_index\")\n",
    "            print(\"last_predicted_word_index: {}\".format(last_predicted_word_index))\n",
    "            \n",
    "            if last_predicted_word_index == EOS_INDEX:\n",
    "                break\n",
    "                \n",
    "        predicted_sequence = tf.stack(\n",
    "            values=predicted_words, axis=1, name='stack')\n",
    "        \n",
    "        return predicted_sequence\n",
    "\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        # input variable - text sequence converted to an index sequence\n",
    "        self.input_sequence = tf.placeholder(\n",
    "            tf.int32, [None, MAX_SEQUENCE_LENGTH], name=\"input_sequence\")\n",
    "        print(\"input_sequence: {}\".format(self.input_sequence))\n",
    "\n",
    "        self.input_label = tf.placeholder(\n",
    "            tf.float32, [None, NUM_LABELS], name=\"input_label\")\n",
    "        print(\"input_label: {}\".format(self.input_label))\n",
    "\n",
    "        # learn embeddings matrix - can be initialized with pre-trained embeddings\n",
    "        word_embeddings = tf.get_variable(\n",
    "            shape=[VOCAB_SIZE + 1, EMBEDDING_SIZE], name=\"word_embeddings\", \n",
    "            dtype=tf.float32)\n",
    "        print(\"word_embeddings: {}\".format(word_embeddings))\n",
    "\n",
    "        # get sentence representation\n",
    "        sentence_representation = self.get_sentence_representation(self.input_sequence, word_embeddings)\n",
    "        print(\"sentence_representation: {}\".format(sentence_representation))\n",
    "\n",
    "        # get content representation\n",
    "        content_representation = self.get_content_representation(sentence_representation)\n",
    "        print(\"content_representation: {}\".format(content_representation))\n",
    "\n",
    "        # use content representation to predict a label\n",
    "        self.label_prediction = self.get_label_prediction(content_representation)\n",
    "        print(\"label_prediction: {}\".format(self.label_prediction))\n",
    "\n",
    "        self.adversarial_loss = tf.losses.softmax_cross_entropy(\n",
    "            onehot_labels=self.input_label, logits=self.label_prediction)\n",
    "        print(\"adversarial_loss: {}\".format(self.adversarial_loss))\n",
    "\n",
    "        self.adversarial_loss_summary = tf.summary.scalar(\n",
    "            tensor=self.adversarial_loss, name=\"adversarial_loss\")\n",
    "\n",
    "        # get style representation\n",
    "        style_representation = self.get_style_representation(sentence_representation)\n",
    "        print(\"style_representation: {}\".format(style_representation))\n",
    "        \n",
    "        # generate new sentence\n",
    "        generated_logits = self.generate_output_sequence(\n",
    "            word_embeddings, style_representation, content_representation)\n",
    "        print(\"generated_logits: {}\".format(generated_logits))\n",
    "        \n",
    "        self.reconstruction_loss = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits=generated_logits, targets=self.input_sequence, \n",
    "            weights=tf.ones(tf.shape(self.input_sequence)), name=\"reconstruction_loss\")\n",
    "        print(\"reconstruction_loss: {}\".format(self.reconstruction_loss))\n",
    "\n",
    "        self.reconstruction_loss_summary = tf.summary.scalar(\n",
    "            tensor=self.reconstruction_loss, name=\"reconstruction_loss\")\n",
    "\n",
    "\n",
    "    def train(self, sess):\n",
    "\n",
    "        writer = tf.summary.FileWriter(logdir=\"tensorflow_logs\")\n",
    "        \n",
    "        adversarial_training_operation = tf.train.AdamOptimizer().minimize(self.adversarial_loss)\n",
    "        \n",
    "        print(tf.trainable_variables())\n",
    "        reconstruction_training_operation = tf.train.AdamOptimizer().minimize(self.reconstruction_loss)\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        epoch_reporting_interval = 1\n",
    "        training_examples_fraction = 0.9\n",
    "        training_examples_size = int(training_examples_fraction * len(one_hot_labels))\n",
    "        batch_size = 100\n",
    "        training_epochs = 10\n",
    "        num_batches = int(training_examples_size/batch_size)\n",
    "\n",
    "        training_step = 1\n",
    "        for current_epoch in range(1, training_epochs + 1):\n",
    "            for batch_number in range(num_batches):\n",
    "                _, adv_loss, adv_loss_sum, _, rec_loss, rec_loss_sum = sess.run(\n",
    "                    [adversarial_training_operation, self.adversarial_loss, self.adversarial_loss_summary,\n",
    "                     reconstruction_training_operation, self.reconstruction_loss, self.reconstruction_loss_summary], \n",
    "                    feed_dict={\n",
    "                        self.input_sequence: padded_sequences[\n",
    "                            batch_number * batch_size : (batch_number + 1) * batch_size],\n",
    "                        self.input_label: one_hot_labels[\n",
    "                            batch_number * batch_size : (batch_number + 1) * batch_size]})\n",
    "                writer.add_summary(adv_loss_sum, training_step)\n",
    "                writer.add_summary(adv_loss_sum, training_step)\n",
    "                writer.flush()\n",
    "                training_step += 1\n",
    "\n",
    "            if (current_epoch % epoch_reporting_interval == 0):\n",
    "                print(\"Training epoch: {}; Adversarial Loss: {}; Reconstruction Loss: {}\"\n",
    "                      .format(current_epoch, adv_loss, rec_loss))\n",
    "\n",
    "        training_predictions = sess.run(\n",
    "            self.label_prediction, \n",
    "            feed_dict={\n",
    "                self.input_sequence: padded_sequences[:training_examples_size], \n",
    "                self.input_label: one_hot_labels[:training_examples_size]\n",
    "            })\n",
    "\n",
    "        test_predictions = sess.run(\n",
    "            self.label_prediction, \n",
    "            feed_dict={\n",
    "                self.input_sequence: padded_sequences[training_examples_size:], \n",
    "                self.input_label: one_hot_labels[training_examples_size:]\n",
    "            })\n",
    "\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sequence: Tensor(\"input_sequence:0\", shape=(?, 100), dtype=int32)\n",
      "input_label: Tensor(\"input_label:0\", shape=(?, 50), dtype=float32)\n",
      "word_embeddings: <tf.Variable 'word_embeddings:0' shape=(1001, 300) dtype=float32_ref>\n",
      "sentence_representation: Tensor(\"concat:0\", shape=(?, 256), dtype=float32)\n",
      "content_representation: Tensor(\"content_representation/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "label_prediction: Tensor(\"label_prediction:0\", shape=(?, 50), dtype=float32)\n",
      "adversarial_loss: Tensor(\"softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n",
      "style_representation: Tensor(\"style_representation/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "generated_logits: Tensor(\"stack:0\", shape=(?, 100, 1001), dtype=float32)\n",
      "reconstruction_loss: Tensor(\"reconstruction_loss/truediv:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "gan = GenerativeAdversarialNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'word_embeddings:0' shape=(1001, 300) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell_fw_content/kernel:0' shape=(428, 512) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/fw/lstm_cell_fw_content/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/lstm_cell_bw_content/kernel:0' shape=(428, 512) dtype=float32_ref>, <tf.Variable 'bidirectional_rnn/bw/lstm_cell_bw_content/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'content_representation/kernel:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'content_representation/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'dense_1/kernel:0' shape=(128, 50) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(50,) dtype=float32_ref>, <tf.Variable 'style_representation/kernel:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'style_representation/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'dense_intermediate_representation/kernel:0' shape=(556, 1001) dtype=float32_ref>, <tf.Variable 'dense_intermediate_representation/bias:0' shape=(1001,) dtype=float32_ref>]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "index innermost dimension length must be <= params rank; saw: 100 vs. 2\n\t [[Node: last_word_embedding_1 = GatherNd[Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](word_embeddings/read, last_word_embedding_1/indices)]]\n\t [[Node: softmax_cross_entropy_loss/value/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5204_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'last_word_embedding_1', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-152-90781ad721a9>\", line 2, in <module>\n    gan = GenerativeAdversarialNetwork()\n  File \"<ipython-input-151-4aadc325bc58>\", line 4, in __init__\n    self.build_model()\n  File \"<ipython-input-151-4aadc325bc58>\", line 140, in build_model\n    word_embeddings, style_representation, content_representation)\n  File \"<ipython-input-151-4aadc325bc58>\", line 53, in generate_output_sequence\n    word_embeddings, [last_predicted_word_index], name='last_word_embedding')\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2000, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): index innermost dimension length must be <= params rank; saw: 100 vs. 2\n\t [[Node: last_word_embedding_1 = GatherNd[Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](word_embeddings/read, last_word_embedding_1/indices)]]\n\t [[Node: softmax_cross_entropy_loss/value/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5204_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: index innermost dimension length must be <= params rank; saw: 100 vs. 2\n\t [[Node: last_word_embedding_1 = GatherNd[Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](word_embeddings/read, last_word_embedding_1/indices)]]\n\t [[Node: softmax_cross_entropy_loss/value/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5204_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-2c859afc5f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-151-4aadc325bc58>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sess)\u001b[0m\n\u001b[1;32m    178\u001b[0m                             batch_number * batch_size : (batch_number + 1) * batch_size],\n\u001b[1;32m    179\u001b[0m                         self.input_label: one_hot_labels[\n\u001b[0;32m--> 180\u001b[0;31m                             batch_number * batch_size : (batch_number + 1) * batch_size]})\n\u001b[0m\u001b[1;32m    181\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_loss_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madv_loss_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: index innermost dimension length must be <= params rank; saw: 100 vs. 2\n\t [[Node: last_word_embedding_1 = GatherNd[Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](word_embeddings/read, last_word_embedding_1/indices)]]\n\t [[Node: softmax_cross_entropy_loss/value/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5204_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'last_word_embedding_1', defined at:\n  File \"/usr/lib64/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib64/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-152-90781ad721a9>\", line 2, in <module>\n    gan = GenerativeAdversarialNetwork()\n  File \"<ipython-input-151-4aadc325bc58>\", line 4, in __init__\n    self.build_model()\n  File \"<ipython-input-151-4aadc325bc58>\", line 140, in build_model\n    word_embeddings, style_representation, content_representation)\n  File \"<ipython-input-151-4aadc325bc58>\", line 53, in generate_output_sequence\n    word_embeddings, [last_predicted_word_index], name='last_word_embedding')\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2000, in gather_nd\n    \"GatherNd\", params=params, indices=indices, name=name)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/v2john/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): index innermost dimension length must be <= params rank; saw: 100 vs. 2\n\t [[Node: last_word_embedding_1 = GatherNd[Tindices=DT_INT64, Tparams=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](word_embeddings/read, last_word_embedding_1/indices)]]\n\t [[Node: softmax_cross_entropy_loss/value/_429 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_5204_softmax_cross_entropy_loss/value\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    gan.train(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
