{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as skp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file_path = \"data/c50-articles.txt\"\n",
    "label_file_path = \"data/c50-labels.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of texts into integer sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokenizer =  tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n",
    "\n",
    "with open(text_file_path) as text_file:\n",
    "    text_tokenizer.fit_on_texts(text_file)\n",
    "    \n",
    "with open(text_file_path) as text_file:\n",
    "    integer_text_sequences = text_tokenizer.texts_to_sequences(text_file)\n",
    "\n",
    "len(integer_text_sequences)\n",
    "\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "     integer_text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "padded_sequences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion of labels to one-hot represenations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer =  tf.keras.preprocessing.text.Tokenizer(lower=False)\n",
    "\n",
    "with open(label_file_path) as label_file:\n",
    "    label_tokenizer.fit_on_texts(label_file)\n",
    "\n",
    "with open(label_file_path) as label_file:\n",
    "    label_sequences = label_tokenizer.texts_to_sequences(label_file)\n",
    "\n",
    "one_hot_labels = list(map(lambda x: np.eye(len(label_tokenizer.word_index), k=x[0])[0], label_sequences))lll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sequence:  Tensor(\"input_sequence:0\", shape=(?, 100), dtype=int32)\n",
      "input_label:  Tensor(\"input_label:0\", shape=(?, 50), dtype=float32)\n",
      "word_embeddings:  <tf.Variable 'word_embeddings:0' shape=(51, 300) dtype=float32_ref>\n",
      "sentence_representation: Tensor(\"concat:0\", shape=(?, 256), dtype=float32)\n",
      "content_representation: Tensor(\"dense_content/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "style_representation: Tensor(\"dense_style/Relu:0\", shape=(?, 128), dtype=float32)\n",
      "label_prediction: Tensor(\"softmax:0\", shape=(?, 50), dtype=float32)\n",
      "Tensor(\"softmax_cross_entropy_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    \n",
    "    # needed to clear the existing graph when the cell is re-run\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    def get_sentence_representation(index_sequence, word_embeddings):\n",
    "\n",
    "        # dense embedded sequence\n",
    "        embedded_sequence = tf.nn.embedding_lookup(\n",
    "            word_embeddings, input_sequence, name=\"embedded_sequence\")\n",
    "\n",
    "        lstm_cell_fw = tf.contrib.rnn.BasicLSTMCell(num_units=128, name=\"lstm_cell_fw_content\")\n",
    "        lstm_cell_bw = tf.contrib.rnn.BasicLSTMCell(num_units=128, name=\"lstm_cell_bw_content\")\n",
    "\n",
    "        rnn_outputs, rnn_states = tf.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=lstm_cell_fw, cell_bw=lstm_cell_bw, inputs=embedded_sequence, \n",
    "            dtype=tf.float32, time_major=False)\n",
    "        rnn_state = tf.concat([rnn_states[0].c, rnn_states[1].c], axis=1)\n",
    "\n",
    "        return rnn_state\n",
    "\n",
    "    def get_content_representation(sentence_representation):\n",
    "        dense_content = tf.layers.dense(\n",
    "            inputs=sentence_representation, units=128, \n",
    "            activation=tf.nn.relu, name=\"dense_content\")\n",
    "        \n",
    "        return dense_content\n",
    "\n",
    "    def get_style_representation(sentence_representation):\n",
    "        dense_style = tf.layers.dense(\n",
    "            inputs=sentence_representation, units=128, \n",
    "            activation=tf.nn.relu, name=\"dense_style\")\n",
    "        \n",
    "        return dense_style\n",
    "\n",
    "    def get_label_prediction(content_representation):\n",
    "\n",
    "        dense_1 = tf.layers.dense(\n",
    "            inputs=content_representation, units=len(label_tokenizer.word_index), \n",
    "            activation=tf.nn.relu, name=\"dense_1\")\n",
    "\n",
    "        softmax_output = tf.nn.softmax(dense_1, name=\"softmax\")\n",
    "\n",
    "        return softmax_output\n",
    "\n",
    "\n",
    "    # input variable - text sequence converted to an index sequence\n",
    "    input_sequence = tf.placeholder(\n",
    "        tf.int32, [None, MAX_SEQUENCE_LENGTH], name=\"input_sequence\")\n",
    "    print(\"input_sequence: \", input_sequence)\n",
    "\n",
    "    input_label = tf.placeholder(\n",
    "        tf.float32, [None, len(label_tokenizer.word_index)], name=\"input_label\")\n",
    "    print(\"input_label: \", input_label)\n",
    "\n",
    "    # learn embeddings matrix - can be initialized with pre-trained embeddings\n",
    "    word_embeddings = tf.get_variable(\n",
    "        shape=[len(label_tokenizer.word_index) + 1, EMBEDDING_SIZE], name=\"word_embeddings\", \n",
    "        dtype=tf.float32)\n",
    "    print(\"word_embeddings: \", word_embeddings)\n",
    "    \n",
    "    # get sentence representation\n",
    "    sentence_representation = get_sentence_representation(input_sequence, word_embeddings)\n",
    "    print(\"sentence_representation:\", sentence_representation)\n",
    "\n",
    "    # get content representation\n",
    "    content_representation = get_content_representation(sentence_representation)\n",
    "    print(\"content_representation:\", content_representation)\n",
    "\n",
    "    # get style representation\n",
    "    style_representation = get_style_representation(sentence_representation)\n",
    "    print(\"style_representation:\", style_representation)\n",
    "\n",
    "    # use content representation to predict a label\n",
    "    label_prediction = get_label_prediction(content_representation)\n",
    "    print(\"label_prediction:\", label_prediction)\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=input_label, logits=label_prediction)\n",
    "    \n",
    "    adversarial_optimizer = tf.train.AdamOptimizer()\n",
    "    adversarial_loss = adversarial_optimizer.minimize(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".pyenv",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
